// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package v1

import (
	"strconv"

	flatbuffers "github.com/google/flatbuffers/go"
)

type DurationUint int8

const (
	DurationUintHour  DurationUint = 0
	DurationUintDay   DurationUint = 1
	DurationUintWeek  DurationUint = 2
	DurationUintMonth DurationUint = 3
)

var EnumNamesDurationUint = map[DurationUint]string{
	DurationUintHour:  "Hour",
	DurationUintDay:   "Day",
	DurationUintWeek:  "Week",
	DurationUintMonth: "Month",
}

var EnumValuesDurationUint = map[string]DurationUint{
	"Hour":  DurationUintHour,
	"Day":   DurationUintDay,
	"Week":  DurationUintWeek,
	"Month": DurationUintMonth,
}

func (v DurationUint) String() string {
	if s, ok := EnumNamesDurationUint[v]; ok {
		return s
	}
	return "DurationUint(" + strconv.FormatInt(int64(v), 10) + ")"
}

type FieldType int8

const (
	FieldTypeString      FieldType = 0
	FieldTypeInt         FieldType = 1
	FieldTypeStringArray FieldType = 2
	FieldTypeIntArray    FieldType = 3
)

var EnumNamesFieldType = map[FieldType]string{
	FieldTypeString:      "String",
	FieldTypeInt:         "Int",
	FieldTypeStringArray: "StringArray",
	FieldTypeIntArray:    "IntArray",
}

var EnumValuesFieldType = map[string]FieldType{
	"String":      FieldTypeString,
	"Int":         FieldTypeInt,
	"StringArray": FieldTypeStringArray,
	"IntArray":    FieldTypeIntArray,
}

func (v FieldType) String() string {
	if s, ok := EnumNamesFieldType[v]; ok {
		return s
	}
	return "FieldType(" + strconv.FormatInt(int64(v), 10) + ")"
}

type Catalog int8

const (
	CatalogTrace  Catalog = 0
	CatalogLog    Catalog = 1
	CatalogMetric Catalog = 2
)

var EnumNamesCatalog = map[Catalog]string{
	CatalogTrace:  "Trace",
	CatalogLog:    "Log",
	CatalogMetric: "Metric",
}

var EnumValuesCatalog = map[string]Catalog{
	"Trace":  CatalogTrace,
	"Log":    CatalogLog,
	"Metric": CatalogMetric,
}

func (v Catalog) String() string {
	if s, ok := EnumNamesCatalog[v]; ok {
		return s
	}
	return "Catalog(" + strconv.FormatInt(int64(v), 10) + ")"
}

type IndexType int8

const (
	IndexTypeText           IndexType = 0
	IndexTypeNumerical      IndexType = 1
	IndexTypeID             IndexType = 2
	IndexTypeMultiText      IndexType = 3
	IndexTypeMultiNumerical IndexType = 4
	IndexTypeSeriesInternal IndexType = 5
)

var EnumNamesIndexType = map[IndexType]string{
	IndexTypeText:           "Text",
	IndexTypeNumerical:      "Numerical",
	IndexTypeID:             "ID",
	IndexTypeMultiText:      "MultiText",
	IndexTypeMultiNumerical: "MultiNumerical",
	IndexTypeSeriesInternal: "SeriesInternal",
}

var EnumValuesIndexType = map[string]IndexType{
	"Text":           IndexTypeText,
	"Numerical":      IndexTypeNumerical,
	"ID":             IndexTypeID,
	"MultiText":      IndexTypeMultiText,
	"MultiNumerical": IndexTypeMultiNumerical,
	"SeriesInternal": IndexTypeSeriesInternal,
}

func (v IndexType) String() string {
	if s, ok := EnumNamesIndexType[v]; ok {
		return s
	}
	return "IndexType(" + strconv.FormatInt(int64(v), 10) + ")"
}

type ShardInfo struct {
	_tab flatbuffers.Table
}

func GetRootAsShardInfo(buf []byte, offset flatbuffers.UOffsetT) *ShardInfo {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &ShardInfo{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsShardInfo(buf []byte, offset flatbuffers.UOffsetT) *ShardInfo {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &ShardInfo{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *ShardInfo) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *ShardInfo) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *ShardInfo) Number() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *ShardInfo) MutateNumber(n uint32) bool {
	return rcv._tab.MutateUint32Slot(4, n)
}

func (rcv *ShardInfo) RoutingFields(j int) []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		a := rcv._tab.Vector(o)
		return rcv._tab.ByteVector(a + flatbuffers.UOffsetT(j*4))
	}
	return nil
}

func (rcv *ShardInfo) RoutingFieldsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func ShardInfoStart(builder *flatbuffers.Builder) {
	builder.StartObject(2)
}
func ShardInfoAddNumber(builder *flatbuffers.Builder, number uint32) {
	builder.PrependUint32Slot(0, number, 0)
}
func ShardInfoAddRoutingFields(builder *flatbuffers.Builder, routingFields flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(routingFields), 0)
}
func ShardInfoStartRoutingFieldsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func ShardInfoEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type Duration struct {
	_tab flatbuffers.Struct
}

func (rcv *Duration) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *Duration) Table() flatbuffers.Table {
	return rcv._tab.Table
}

func (rcv *Duration) Val() uint32 {
	return rcv._tab.GetUint32(rcv._tab.Pos + flatbuffers.UOffsetT(0))
}
func (rcv *Duration) MutateVal(n uint32) bool {
	return rcv._tab.MutateUint32(rcv._tab.Pos+flatbuffers.UOffsetT(0), n)
}

func (rcv *Duration) Unit() DurationUint {
	return DurationUint(rcv._tab.GetInt8(rcv._tab.Pos + flatbuffers.UOffsetT(4)))
}
func (rcv *Duration) MutateUnit(n DurationUint) bool {
	return rcv._tab.MutateInt8(rcv._tab.Pos+flatbuffers.UOffsetT(4), int8(n))
}

func CreateDuration(builder *flatbuffers.Builder, val uint32, unit DurationUint) flatbuffers.UOffsetT {
	builder.Prep(4, 8)
	builder.Pad(3)
	builder.PrependInt8(int8(unit))
	builder.PrependUint32(val)
	return builder.Offset()
}

type FieldSpec struct {
	_tab flatbuffers.Table
}

func GetRootAsFieldSpec(buf []byte, offset flatbuffers.UOffsetT) *FieldSpec {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &FieldSpec{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsFieldSpec(buf []byte, offset flatbuffers.UOffsetT) *FieldSpec {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &FieldSpec{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *FieldSpec) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *FieldSpec) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *FieldSpec) Name() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func (rcv *FieldSpec) Type() FieldType {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return FieldType(rcv._tab.GetInt8(o + rcv._tab.Pos))
	}
	return 0
}

func (rcv *FieldSpec) MutateType(n FieldType) bool {
	return rcv._tab.MutateInt8Slot(6, int8(n))
}

func FieldSpecStart(builder *flatbuffers.Builder) {
	builder.StartObject(2)
}
func FieldSpecAddName(builder *flatbuffers.Builder, name flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(name), 0)
}
func FieldSpecAddType(builder *flatbuffers.Builder, type_ FieldType) {
	builder.PrependInt8Slot(1, int8(type_), 0)
}
func FieldSpecEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type TraceStateMap struct {
	_tab flatbuffers.Table
}

func GetRootAsTraceStateMap(buf []byte, offset flatbuffers.UOffsetT) *TraceStateMap {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &TraceStateMap{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsTraceStateMap(buf []byte, offset flatbuffers.UOffsetT) *TraceStateMap {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &TraceStateMap{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *TraceStateMap) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *TraceStateMap) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *TraceStateMap) Field() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func (rcv *TraceStateMap) ValSuccess() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func (rcv *TraceStateMap) ValError() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func TraceStateMapStart(builder *flatbuffers.Builder) {
	builder.StartObject(3)
}
func TraceStateMapAddField(builder *flatbuffers.Builder, field flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(field), 0)
}
func TraceStateMapAddValSuccess(builder *flatbuffers.Builder, valSuccess flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(valSuccess), 0)
}
func TraceStateMapAddValError(builder *flatbuffers.Builder, valError flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(2, flatbuffers.UOffsetT(valError), 0)
}
func TraceStateMapEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type TraceFieldMap struct {
	_tab flatbuffers.Table
}

func GetRootAsTraceFieldMap(buf []byte, offset flatbuffers.UOffsetT) *TraceFieldMap {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &TraceFieldMap{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsTraceFieldMap(buf []byte, offset flatbuffers.UOffsetT) *TraceFieldMap {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &TraceFieldMap{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *TraceFieldMap) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *TraceFieldMap) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *TraceFieldMap) TraceId() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func (rcv *TraceFieldMap) SeriesId(j int) []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		a := rcv._tab.Vector(o)
		return rcv._tab.ByteVector(a + flatbuffers.UOffsetT(j*4))
	}
	return nil
}

func (rcv *TraceFieldMap) SeriesIdLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *TraceFieldMap) State(obj *TraceStateMap) *TraceStateMap {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(TraceStateMap)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func TraceFieldMapStart(builder *flatbuffers.Builder) {
	builder.StartObject(3)
}
func TraceFieldMapAddTraceId(builder *flatbuffers.Builder, traceId flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(traceId), 0)
}
func TraceFieldMapAddSeriesId(builder *flatbuffers.Builder, seriesId flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(seriesId), 0)
}
func TraceFieldMapStartSeriesIdVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func TraceFieldMapAddState(builder *flatbuffers.Builder, state flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(2, flatbuffers.UOffsetT(state), 0)
}
func TraceFieldMapEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type TraceSeries struct {
	_tab flatbuffers.Table
}

func GetRootAsTraceSeries(buf []byte, offset flatbuffers.UOffsetT) *TraceSeries {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &TraceSeries{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsTraceSeries(buf []byte, offset flatbuffers.UOffsetT) *TraceSeries {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &TraceSeries{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *TraceSeries) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *TraceSeries) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *TraceSeries) Metadata(obj *Metadata) *Metadata {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Metadata)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *TraceSeries) Fields(obj *FieldSpec, j int) bool {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		x := rcv._tab.Vector(o)
		x += flatbuffers.UOffsetT(j) * 4
		x = rcv._tab.Indirect(x)
		obj.Init(rcv._tab.Bytes, x)
		return true
	}
	return false
}

func (rcv *TraceSeries) FieldsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *TraceSeries) ReservedFieldsMap(obj *TraceFieldMap) *TraceFieldMap {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(TraceFieldMap)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *TraceSeries) Shard(obj *ShardInfo) *ShardInfo {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(ShardInfo)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *TraceSeries) Duration(obj *Duration) *Duration {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		x := o + rcv._tab.Pos
		if obj == nil {
			obj = new(Duration)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *TraceSeries) UpdatedAtNanoseconds() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *TraceSeries) MutateUpdatedAtNanoseconds(n uint64) bool {
	return rcv._tab.MutateUint64Slot(14, n)
}

func TraceSeriesStart(builder *flatbuffers.Builder) {
	builder.StartObject(6)
}
func TraceSeriesAddMetadata(builder *flatbuffers.Builder, metadata flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(metadata), 0)
}
func TraceSeriesAddFields(builder *flatbuffers.Builder, fields flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(fields), 0)
}
func TraceSeriesStartFieldsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func TraceSeriesAddReservedFieldsMap(builder *flatbuffers.Builder, reservedFieldsMap flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(2, flatbuffers.UOffsetT(reservedFieldsMap), 0)
}
func TraceSeriesAddShard(builder *flatbuffers.Builder, shard flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(3, flatbuffers.UOffsetT(shard), 0)
}
func TraceSeriesAddDuration(builder *flatbuffers.Builder, duration flatbuffers.UOffsetT) {
	builder.PrependStructSlot(4, flatbuffers.UOffsetT(duration), 0)
}
func TraceSeriesAddUpdatedAtNanoseconds(builder *flatbuffers.Builder, updatedAtNanoseconds uint64) {
	builder.PrependUint64Slot(5, updatedAtNanoseconds, 0)
}
func TraceSeriesEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type IndexObject struct {
	_tab flatbuffers.Table
}

func GetRootAsIndexObject(buf []byte, offset flatbuffers.UOffsetT) *IndexObject {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &IndexObject{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsIndexObject(buf []byte, offset flatbuffers.UOffsetT) *IndexObject {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &IndexObject{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *IndexObject) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *IndexObject) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *IndexObject) Name() []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.ByteVector(o + rcv._tab.Pos)
	}
	return nil
}

func (rcv *IndexObject) Fields(j int) []byte {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		a := rcv._tab.Vector(o)
		return rcv._tab.ByteVector(a + flatbuffers.UOffsetT(j*4))
	}
	return nil
}

func (rcv *IndexObject) FieldsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *IndexObject) Type() IndexType {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return IndexType(rcv._tab.GetInt8(o + rcv._tab.Pos))
	}
	return 0
}

func (rcv *IndexObject) MutateType(n IndexType) bool {
	return rcv._tab.MutateInt8Slot(8, int8(n))
}

func IndexObjectStart(builder *flatbuffers.Builder) {
	builder.StartObject(3)
}
func IndexObjectAddName(builder *flatbuffers.Builder, name flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(name), 0)
}
func IndexObjectAddFields(builder *flatbuffers.Builder, fields flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(fields), 0)
}
func IndexObjectStartFieldsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func IndexObjectAddType(builder *flatbuffers.Builder, type_ IndexType) {
	builder.PrependInt8Slot(2, int8(type_), 0)
}
func IndexObjectEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type IndexRule struct {
	_tab flatbuffers.Table
}

func GetRootAsIndexRule(buf []byte, offset flatbuffers.UOffsetT) *IndexRule {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &IndexRule{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsIndexRule(buf []byte, offset flatbuffers.UOffsetT) *IndexRule {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &IndexRule{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *IndexRule) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *IndexRule) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *IndexRule) Metadata(obj *Metadata) *Metadata {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Metadata)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *IndexRule) Objects(obj *IndexObject, j int) bool {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		x := rcv._tab.Vector(o)
		x += flatbuffers.UOffsetT(j) * 4
		x = rcv._tab.Indirect(x)
		obj.Init(rcv._tab.Bytes, x)
		return true
	}
	return false
}

func (rcv *IndexRule) ObjectsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *IndexRule) UpdatedAtNanoseconds() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *IndexRule) MutateUpdatedAtNanoseconds(n uint64) bool {
	return rcv._tab.MutateUint64Slot(8, n)
}

func IndexRuleStart(builder *flatbuffers.Builder) {
	builder.StartObject(3)
}
func IndexRuleAddMetadata(builder *flatbuffers.Builder, metadata flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(metadata), 0)
}
func IndexRuleAddObjects(builder *flatbuffers.Builder, objects flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(objects), 0)
}
func IndexRuleStartObjectsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func IndexRuleAddUpdatedAtNanoseconds(builder *flatbuffers.Builder, updatedAtNanoseconds uint64) {
	builder.PrependUint64Slot(2, updatedAtNanoseconds, 0)
}
func IndexRuleEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type Series struct {
	_tab flatbuffers.Table
}

func GetRootAsSeries(buf []byte, offset flatbuffers.UOffsetT) *Series {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &Series{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsSeries(buf []byte, offset flatbuffers.UOffsetT) *Series {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &Series{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *Series) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *Series) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *Series) Catalog() Catalog {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return Catalog(rcv._tab.GetInt8(o + rcv._tab.Pos))
	}
	return 0
}

func (rcv *Series) MutateCatalog(n Catalog) bool {
	return rcv._tab.MutateInt8Slot(4, int8(n))
}

func (rcv *Series) Series(obj *Metadata) *Metadata {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Metadata)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func SeriesStart(builder *flatbuffers.Builder) {
	builder.StartObject(2)
}
func SeriesAddCatalog(builder *flatbuffers.Builder, catalog Catalog) {
	builder.PrependInt8Slot(0, int8(catalog), 0)
}
func SeriesAddSeries(builder *flatbuffers.Builder, series flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(series), 0)
}
func SeriesEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}

type IndexRuleBinding struct {
	_tab flatbuffers.Table
}

func GetRootAsIndexRuleBinding(buf []byte, offset flatbuffers.UOffsetT) *IndexRuleBinding {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &IndexRuleBinding{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsIndexRuleBinding(buf []byte, offset flatbuffers.UOffsetT) *IndexRuleBinding {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &IndexRuleBinding{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *IndexRuleBinding) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *IndexRuleBinding) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *IndexRuleBinding) Metadata(obj *Metadata) *Metadata {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Metadata)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *IndexRuleBinding) RuleRef(obj *Metadata) *Metadata {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		x := rcv._tab.Indirect(o + rcv._tab.Pos)
		if obj == nil {
			obj = new(Metadata)
		}
		obj.Init(rcv._tab.Bytes, x)
		return obj
	}
	return nil
}

func (rcv *IndexRuleBinding) Subjects(obj *Series, j int) bool {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		x := rcv._tab.Vector(o)
		x += flatbuffers.UOffsetT(j) * 4
		x = rcv._tab.Indirect(x)
		obj.Init(rcv._tab.Bytes, x)
		return true
	}
	return false
}

func (rcv *IndexRuleBinding) SubjectsLength() int {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.VectorLen(o)
	}
	return 0
}

func (rcv *IndexRuleBinding) BeginAtNanoseconds() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *IndexRuleBinding) MutateBeginAtNanoseconds(n uint64) bool {
	return rcv._tab.MutateUint64Slot(10, n)
}

func (rcv *IndexRuleBinding) ExpireAtNanoseconds() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *IndexRuleBinding) MutateExpireAtNanoseconds(n uint64) bool {
	return rcv._tab.MutateUint64Slot(12, n)
}

func (rcv *IndexRuleBinding) UpdatedAtNanoseconds() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *IndexRuleBinding) MutateUpdatedAtNanoseconds(n uint64) bool {
	return rcv._tab.MutateUint64Slot(14, n)
}

func IndexRuleBindingStart(builder *flatbuffers.Builder) {
	builder.StartObject(6)
}
func IndexRuleBindingAddMetadata(builder *flatbuffers.Builder, metadata flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(0, flatbuffers.UOffsetT(metadata), 0)
}
func IndexRuleBindingAddRuleRef(builder *flatbuffers.Builder, ruleRef flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(1, flatbuffers.UOffsetT(ruleRef), 0)
}
func IndexRuleBindingAddSubjects(builder *flatbuffers.Builder, subjects flatbuffers.UOffsetT) {
	builder.PrependUOffsetTSlot(2, flatbuffers.UOffsetT(subjects), 0)
}
func IndexRuleBindingStartSubjectsVector(builder *flatbuffers.Builder, numElems int) flatbuffers.UOffsetT {
	return builder.StartVector(4, numElems, 4)
}
func IndexRuleBindingAddBeginAtNanoseconds(builder *flatbuffers.Builder, beginAtNanoseconds uint64) {
	builder.PrependUint64Slot(3, beginAtNanoseconds, 0)
}
func IndexRuleBindingAddExpireAtNanoseconds(builder *flatbuffers.Builder, expireAtNanoseconds uint64) {
	builder.PrependUint64Slot(4, expireAtNanoseconds, 0)
}
func IndexRuleBindingAddUpdatedAtNanoseconds(builder *flatbuffers.Builder, updatedAtNanoseconds uint64) {
	builder.PrependUint64Slot(5, updatedAtNanoseconds, 0)
}
func IndexRuleBindingEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
